{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa8f9ece",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "584f1eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bessiezhang/Documents/CS 329T/Factcheck-GPT/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying gpt\n",
      "[\"Harris will not ban fracking.\", \"Harris has not banned fracking as Vice President of the United States.\"]\n",
      "['Harris will not ban fracking.', 'Harris has not banned fracking as Vice President of the United States.']\n",
      "CLAIMS DONE\n",
      "Trying gpt\n",
      "To verify the statement \"Harris will not ban fracking,\" you can follow these steps:\n",
      "\n",
      "1. Google: \"Harris stance on fracking\"\n",
      "2. Google: \"Will Kamala Harris ban fracking?\"\n",
      "3. Google: \"Kamala Harris fracking policy\"\n",
      "\n",
      "These search queries should lead you to information about Vice President Kamala Harris's position on fracking, any public statements she might have made on the topic, and her policy views as reported in news articles, interviews, or official statements.\n",
      "These search queries should lead you to information about Vice President Kamala Harris's position on fracking, any public statements she might have made on the topic, and her policy views as reported in news articles, interviews, or official statements.\n",
      "It seems like the last prompt was incomplete. If you want to verify the statement \"Harris will not ban fracking,\" you could perform searches like:\n",
      "\n",
      "1. I googled: \"Harris stance on fracking\"\n",
      "2. I googled: \"Did Harris propose a fracking ban?\"\n",
      "3. I googled: \"Harris fracking policy\"\n",
      "\n",
      "These searches should help you find credible sources discussing Vice President Kamala Harris's policy or statements regarding fracking, clarifying whether she has proposed a ban on it or not.\n",
      "These searches should help you find credible sources discussing Vice President Kamala Harris's policy or statements regarding fracking, clarifying whether she has proposed a ban on it or not.\n",
      "['\"Did Harris propose a fracking ban?\"', '\"Harris fracking policy\"', '\"Harris stance on fracking\"']\n",
      "['\"Harris stance on fracking\"']\n",
      "To verify the statement about Vice President Harris and fracking, you can:\n",
      "1. Google: \"Has Vice President Harris banned fracking?\"\n",
      "2. Search news sources for any official statements or policy changes regarding fracking under the current administration.\n",
      "\n",
      "This approach will help you find the most accurate and up-to-date information on the topic.\n",
      "This approach will help you find the most accurate and up-to-date information on the topic.\n",
      "It seems like you were ready to verify the statement about Vice President Harris and fracking but didn't complete the search query. Here's how you can proceed:\n",
      "\n",
      "1. You might google: \"Has Vice President Harris banned fracking?\"\n",
      "2. You could also search for: \"Vice President Harris stance on fracking.\"\n",
      "\n",
      "These searches should help you verify whether Vice President Harris has implemented any policies regarding fracking since taking office.\n",
      "These searches should help you verify whether Vice President Harris has implemented any policies regarding fracking since taking office.\n",
      "1. I googled: Has Vice President Harris banned fracking?\n",
      "\n",
      "Based on the searches you conducted, it seems like you've structured your queries well to verify the information provided. Each question is targeted to address specific claims or facts, which should yield clear and specific answers from reliable sources. If any of the information proves incorrect or ambiguous based on your search results, it would be helpful to cross-reference with additional credible sources or adjust the search queries for more precision.\n",
      "Based on the searches you conducted, it seems like you've structured your queries well to verify the information provided. Each question is targeted to address specific claims or facts, which should yield clear and specific answers from reliable sources. If any of the information proves incorrect or ambiguous based on your search results, it would be helpful to cross-reference with additional credible sources or adjust the search queries for more precision.\n",
      "To verify the statement about Vice President Harris not banning fracking, you can search:\n",
      "\n",
      "1. \"Has Vice President Harris banned fracking?\"\n",
      "2. \"Vice President Harris stance on fracking.\"\n",
      "3. \"Recent fracking legislation by Vice President Harris.\"\n",
      "\n",
      "These search queries should provide you with information about any actions or public statements made by Vice President Harris regarding fracking during her tenure.\n",
      "These search queries should provide you with information about any actions or public statements made by Vice President Harris regarding fracking during her tenure.\n",
      "['Has Vice President Harris banned fracking?']\n",
      "['Has Vice President Harris banned fracking?']\n",
      "Trying gpt\n",
      "Trying gpt\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"./src\")\n",
    "\n",
    "import pandas as pd\n",
    "# from decompose import doc2sentences\n",
    "# from checkworthy import identify_checkworthiness, specify_checkworthiness_type\n",
    "# from retrieve import get_web_evidences_for_claim\n",
    "# from verify import verify_claim\n",
    "from pipeline import check_document, check_documents\n",
    "\n",
    "doc = \"Harris will not ban fracking. Harris have not banned fracking as Vice President of the United States.\" \n",
    "label, log = check_document(doc, model = \"gpt-4-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "434421cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b9a531d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e59737",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baselines import evaluate_revisions, subtask5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f113be",
   "metadata": {},
   "source": [
    "### Subtask 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e38f73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtask5(datadir=\"./test/subtask5_revision.jsonl\", savedir=\"./test/result/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1daa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluate_revisions(datadir=\"./test/result/st5.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d95ba6",
   "metadata": {},
   "source": [
    "#### Human Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547d29f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "unshuffledir = \"./subtasks_data/result/st5_human_eval/\"\n",
    "\n",
    "human_prefer = []\n",
    "for i in range(61):\n",
    "    temp = pd.read_json(os.path.join(unshuffledir, f\"{i}.json\"), typ=\"series\")\n",
    "    hls = temp[\"human_preference\"].split(\",\")\n",
    "    # for some examples, preference is more than one, separated by comma\n",
    "    if len(hls) > 1:\n",
    "        hls = [s.strip() for s in hls]\n",
    "        print(i, hls)\n",
    "    human_prefer += hls\n",
    "print(len(human_prefer))\n",
    "Counter(human_prefer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa119df",
   "metadata": {},
   "source": [
    "### Subtask 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aafadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assess Factool: https://github.com/GAIR-NLP/factool.git in subtask 4;\n",
    "# Web source setting serper or our pipeline retriever with Google search results\n",
    "# Wikipedia setting: calling the Factscore retriever based on wikipedia database\n",
    "\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = \"set_openai_key\"\n",
    "os.environ['SERPAPI_API_KEY'] = \"set_serpapi_key\"\n",
    "from factool.knowledge_qa.pipeline import knowledge_qa_pipeline\n",
    "\n",
    "def run_subtask4(claim):\n",
    "    foundation_model = \"gpt-3.5-turbo\"\n",
    "    kbqa_pipeline = knowledge_qa_pipeline(foundation_model, 10, \"online\")\n",
    "    claims = [{\"claim\": claim}]\n",
    "    output = asyncio.run(kbqa_pipeline.run_with_tool_live_without_claim_extraction(claims))\n",
    "    return output[0][\"factuality\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92382e3b",
   "metadata": {},
   "source": [
    "### Subtask 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a35005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0544dcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baselines import nli_predict_stance, eval_subtask3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915edef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold, predictions, metrics = \\\n",
    "nli_predict_stance(datadir=\"./subtasks_data/subtask3_claim_evidence_stance.jsonl\", \n",
    "                   savedir=\"./subtasks_data/result/st3_roberta_mnli.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38b36c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b082e666",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold, preds, metrics = \\\n",
    "eval_subtask3(datadir=\"./subtasks_data/subtask3_claim_evidence_stance.jsonl\", \n",
    "              response_savedir=\"./subtasks_data/result/st3_gpt3.5_zs.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55af2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d25a1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold, predictions, metrics = \\\n",
    "nli_predict_stance(datadir=\"./test/subtask3_claim_evidence_stance.jsonl\", \n",
    "                   savedir=\"./test/result/st3_roberta_mnli.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5600b744",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c079e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold, preds, metrics = \\\n",
    "eval_subtask3(datadir=\"./test/subtask3_claim_evidence_stance.jsonl\", \n",
    "              response_savedir=\"./test/result/st3_gpt3.5_zs.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92475c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827dc5bc",
   "metadata": {},
   "source": [
    "### Subtask 1 and 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e88ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baselines import eval_sentence_checkworthiness, eval_claim_checkworthiness, all_checkworthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18305c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, gold, metrics = eval_sentence_checkworthiness(\n",
    "    datadir=\"./subtasks_data/subtask1_sentence_checkworthiness.jsonl\",\n",
    "    response_savedir=\"./subtasks_data/result/st1_gpt3.5_zs.json\")\n",
    "\n",
    "\n",
    "preds, gold, metrics = eval_claim_checkworthiness(\n",
    "    datadir=\"./subtasks_data/subtask2_claim_checkworthiness.jsonl\",\n",
    "    response_savedir=\"./subtasks_data/result/st2_gpt3.5_zs.json\")\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5cd752",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_checkworthy(datadir = \"./subtasks_data/subtask1_sentence_checkworthiness.jsonl\", \n",
    "                granularity=\"sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ab602b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_checkworthy(datadir = \"./subtasks_data/subtask2_claim_checkworthiness.jsonl\", \n",
    "                granularity=\"claim\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
